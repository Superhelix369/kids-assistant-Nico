import sounddevice as sd
import numpy as np
import scipy.io.wavfile as wav
import openai
import time
import os
import simpleaudio as sa
import requests
import random
import sys

from config import OPENAI_API_KEY, ASSISTANT_ID

# VoiceVox ã®ãƒ›ã‚¹ãƒˆï¼ˆElastic IPï¼‰ã‚’ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã§å—ã‘å–ã‚‹
if len(sys.argv) < 2:
    print("âŒ ã‚¨ãƒ©ãƒ¼: VoiceVox ã®ãƒ›ã‚¹ãƒˆï¼ˆElastic IPï¼‰ã‚’ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã§æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")
    sys.exit(config.SPEAKER_ID)

VOICEVOX_PORT = config.VOICEVOX_PORT
VOICEVOX_HOST = sys.argv[config.SPEAKER_ID]
VOICEVOX_URL = f"http://{VOICEVOX_HOST}:{VOICEVOX_PORT}"
print(f"âœ… VoiceVox ãƒ›ã‚¹ãƒˆã¨ã—ã¦ '{VOICEVOX_HOST}' ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")


# OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
client = openai.OpenAI(api_key=OPENAI_API_KEY)

# è¨­å®š
INACTIVITY_TIMEOUT = 300
SAMPLERATE = 48000
DURATION = 5
FILENAME = "input.wav"
SPEAKER_ID = config.SPEAKER_ID
INPUT_DEVICE = 0  # â† é©åˆ‡ãªå…¥åŠ›ãƒ‡ãƒã‚¤ã‚¹ç•ªå·ã«å¤‰æ›´ï¼ˆsounddevice -m ã§ç¢ºèªæ¸ˆã¿ï¼‰


STOP_WORDS = ["stop", "ã‚¹ãƒˆãƒƒãƒ—", "ã™ã¨ã£ã·", "Stop"]
IGNORE_WORDS = [
    "ã”è¦–è´ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸ", "ã”æ¸…è´ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸ",
    "æœ€å¾Œã¾ã§è¦–è´ã—ã¦ãã ã•ã£ã¦æœ¬å½“ã«ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™",
    "æœ¬æ—¥ã¯ã”è¦–è´ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸ",
    "ã”è¦–è´ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸï¼", "ã”è¦–è´ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸ!",
    "ğŸ¯ Sound Hodori ì‚¬ìš´ë“œ í˜¸ë„ë¦¬ ã‚µã‚¦ãƒ³ãƒ‰ã‚¥ ãƒ›ãƒ‰ãƒª",
    "ãŠã—ã¾ã„ã€‚ã”è¦–è´ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸã€‚",
    "æœ€å¾Œã¾ã§è¦–è´ã—ã¦ãã ã•ã£ã¦ æœ¬å½“ã«ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚",
    "æœ€å¾Œã¾ã§ã”è¦–è´ã„ãŸã ãã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã„ã¾ã™ã€‚",
    "ãƒ€ãƒ¡ã§ã™",
    "ãŠã‚„ã™ã¿ãªã•ã„ã€‚",
    "ãŠã‚„ã™ã¿ãªã•ã„",
    "ã¾ãŸä¼šã„ã¾ã—ã‚‡ã†ã€‚"    
]

GREETINGS = [
    "ã‚ãã¼ï¼ã‚ãã¼ãƒ¼ï¼", "ã‚„ã£ãŸãƒ¼ï¼ãŠã—ã‚ƒã¹ã‚Šã—ã‚ˆãƒ¼", "ã‚„ã£ã»ãƒ¼ï¼ã“ã‚“ã«ã¡ã¯",
    "ã¡ã‚‡ã£ã¨ã­ã‚€ãŸã„ã‚ˆãƒ¼", "ãªã«ï¼Ÿãªã«ï¼Ÿã©ã†ã—ãŸã®ï¼Ÿ", "ã­ãˆã­ãˆã€ã“ã£ã¡ã¿ã¦ãƒ¼",
    "ã©ã†ã—ãŸã®ï¼Ÿ", "ã‚ˆãå¯ãŸï½!", "ã‚ãƒ¼ã„ï¼ã‚ãƒ¼ã„ï¼ãŠã­ãˆã¡ã‚ƒã‚“ï¼", "ãŠãªã‹ã—ã‚…ã„ãŸ"
]


# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‡ãƒã‚¤ã‚¹ã‚’è¨­å®šï¼ˆçœç•¥ã‚‚å¯ã ãŒå¿µã®ãŸã‚ï¼‰
sd.default.device = (INPUT_DEVICE, None)


# ------------------ éŸ³å£°é–¢é€£ ------------------ #

def record_audio():
    try:
        if os.path.exists(FILENAME):
            os.remove(FILENAME)

        audio = sd.rec(
            int(SAMPLERATE * DURATION),
            samplerate=SAMPLERATE,
            channels=config.SPEAKER_ID,
            dtype=np.int16,
            device=INPUT_DEVICE
        )
        sd.wait()
        wav.write(FILENAME, SAMPLERATE, audio)
        return True
    except Exception as e:
        print("âŒ éŒ²éŸ³ã‚¨ãƒ©ãƒ¼:", e)
        return False


def transcribe_audio():
    try:
        with open(FILENAME, "rb") as f:
            response = client.audio.transcriptions.create(
                model="whisper-config.SPEAKER_ID", file=f, language="ja", temperature=0.0
            )
        return response.text.strip()
    except Exception as e:
        print("âŒ éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼:", e)
        return ""

# ------------------ Assistant API ------------------ #

def create_assistant_thread():
    return client.beta.threads.create().id

def get_assistant_response(thread_id, user_input):
    try:
        client.beta.threads.messages.create(thread_id=thread_id, role="user", content=user_input)
        run = client.beta.threads.runs.create(thread_id=thread_id, assistant_id=ASSISTANT_ID)

        while True:
            run_status = client.beta.threads.runs.retrieve(thread_id=thread_id, run_id=run.id)
            if run_status.status == "completed":
                break
            time.sleep(0.5)

        messages = client.beta.threads.messages.list(thread_id=thread_id)
        return messages.data[0].content[0].text.value
    except Exception as e:
        print("âŒ Assistant API ã‚¨ãƒ©ãƒ¼:", e)
        return "ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"

# ------------------ Voicevox ------------------ #

def synthesize_voice(text, speaker):
    try:
        params = {"text": text, "speaker": speaker}
        query_res = requests.post(f"{VOICEVOX_URL}/audio_query", params=params)
        if query_res.status_code != 200:
            print("âŒ ã‚¯ã‚¨ãƒªä½œæˆå¤±æ•—:", query_res.text)
            return None
        query = query_res.json()
        query.update({
            "speedScale": 1.1,
            "intonationScale": 1.6,
            "pitchScale": 0,
            "volumeScale": 1.0,
            "prePhonemeLength": 0,
            "postPhonemeLength": 0
        })
        synth_res = requests.post(f"{VOICEVOX_URL}/synthesis", params=params, json=query)
        if synth_res.status_code != 200:
            print("âŒ éŸ³å£°åˆæˆå¤±æ•—:", synth_res.text)
            return None
        return synth_res.content
    except Exception as e:
        print("âŒ Voicevoxã‚¨ãƒ©ãƒ¼:", e)
        return None

def amplify_audio(audio_data, factor):
    audio_array = np.frombuffer(audio_data, dtype=np.int16)
    amplified = (audio_array * factor).clip(-32768, 32767).astype(np.int16)
    return amplified.tobytes()

def play_audio(audio_data, factor=1.2):
    amplified = amplify_audio(audio_data, factor)
    wave = sa.WaveObject(amplified, num_channels=config.SPEAKER_ID, bytes_per_sample=2, sample_rate=24000)
    play = wave.play()
    play.wait_done()


# ------------------ ãƒ¡ã‚¤ãƒ³ä¼šè©±ãƒ«ãƒ¼ãƒ— ------------------ #

def speak_greeting():
    greeting = random.choice(GREETINGS)
    print(f"ğŸ™ï¸ ã‚ã„ã•ã¤: {greeting}")
    audio = synthesize_voice(greeting, SPEAKER_ID)
    if audio:
        play_audio(audio)

def speak_response(text):
    print(f"ğŸ¤– ãƒ‹ã‚³: {text}")
    audio = synthesize_voice(text, SPEAKER_ID)
    if audio:
        play_audio(audio)
    else:
        print("âš  éŸ³å£°å†ç”Ÿã‚¹ã‚­ãƒƒãƒ—ï¼ˆéŸ³å£°åˆæˆå¤±æ•—ï¼‰")

def listen_and_talk_loop():
    last_valid_input_time = time.time()
    speak_greeting()
    thread_id = create_assistant_thread()

    while True:
        if not record_audio():
            time.sleep(config.SPEAKER_ID)
            continue

        text = transcribe_audio()
        now = time.time()

        if os.path.exists(FILENAME):
            os.remove(FILENAME)

        if not text:
            print("ï¼ˆç„¡éŸ³èªè­˜ï¼‰")
        elif any(word in text for word in IGNORE_WORDS):
            print("ï¼ˆç„¡è¦–ãƒ¯ãƒ¼ãƒ‰æ¤œå‡ºï¼‰")
        else:
            print(f"ğŸ“ ãƒ¦ãƒ¼ã‚¶ãƒ¼: {text}")
            if any(stop_word in text for stop_word in STOP_WORDS):
                print("ğŸ‘‹ ã€ã‚¹ãƒˆãƒƒãƒ—ã€ã‚’æ¤œå‡ºã€‚ä¼šè©±ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
                speak_response("ã¾ãŸã­")
                print("STOP")
                sys.exit(0)
            reply = get_assistant_response(thread_id, text)
            if not reply:
                reply = "ã†ã¾ãç­”ãˆã‚‰ã‚Œãªã‹ã£ãŸã‚ˆã€‚ã‚‚ã†ä¸€å›è¨€ã£ã¦ã¿ã¦ï¼Ÿ"
            speak_response(reply)
            last_valid_input_time = now

        if now - last_valid_input_time > INACTIVITY_TIMEOUT:
            print("â³ 300ç§’é–“æœ‰åŠ¹ãªä¼šè©±ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚çµ‚äº†ã—ã¾ã™ã€‚")
            speak_response("ã¾ãŸã­")
            print("STOP")
            sys.exit(0)
            # å­ä¾›ãŒã€Œã‚¹ãƒˆãƒƒãƒ—ã€ã¨è¨€ã£ãŸã‚‰ã€assistantã‚’çµ‚äº†ï¼ˆmain.pyå´ã§ç›£è¦–ã•ã‚Œã¦ã„ã‚‹ï¼‰


        time.sleep(0.5) #ãŠãã‚‰ãCPUç¨¼åƒç‡ã‚’ä¸‹ã’ã‚‹ãŸã‚ï¼Ÿã§ã‚‚å¿…è¦ãªã„ã‹ã‚‚ã€‚ãªã„æ–¹ãŒå¿œç­”é€Ÿåº¦å‘ä¸Šï¼Ÿ

if __name__ == "__main__":
    try:
        listen_and_talk_loop()
    except KeyboardInterrupt:
        print("ğŸ›‘ ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰å‰²ã‚Šè¾¼ã¿ã«ã‚ˆã‚Šçµ‚äº†")
    except Exception as e:
        print(f"âŒ æœªå‡¦ç†ã®ä¾‹å¤–:", e)
    finally:
        print("ğŸ§¹ assistant.py ã‚’çµ‚äº†ã—ã¾ã™")
        sys.exit(0)

