import sounddevice as sd
import numpy as np
import scipy.io.wavfile as wav
import openai
import time
import os
import requests
import simpleaudio as sa
import random
import sys

from config import OPENAI_API_KEY, ASSISTANT_ID

# OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
client = openai.OpenAI(api_key=OPENAI_API_KEY)

# è¨­å®š
INACTIVITY_TIMEOUT = 300  # 300ç§’ï¼ˆ5åˆ†ï¼‰
SAMPLERATE = 16000
DURATION = 5
FILENAME = "input.wav"
SPEAKER_ID = config.SPEAKER_ID

# Voicevox ãƒ›ã‚¹ãƒˆè¨­å®š
VOICEVOX_PORT = config.VOICEVOX_PORT
VOICEVOX_HOST = sys.argv[config.SPEAKER_ID] if len(sys.argv) > config.SPEAKER_ID else "localhost"
VOICEVOX_URL = f"http://{VOICEVOX_HOST}:{VOICEVOX_PORT}"

STOP_WORDS = ["stop", "ã‚¹ãƒˆãƒƒãƒ—", "ã™ã¨ã£ã·", "Stop"]
IGNORE_WORDS = [
    "ã”è¦–è´ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸ", 
    "ã”è¦–è´ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸã€‚",
    "ã”æ¸…è´ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸ", 
    "æœ€å¾Œã¾ã§è¦–è´ã—ã¦ãã ã•ã£ã¦æœ¬å½“ã«ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™",
    "æœ¬æ—¥ã¯ã”è¦–è´ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸ",
    "ã”è¦–è´ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸï¼",
    "ã”è¦–è´ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸ!",
    "ğŸ¯ Sound Hodori ì‚¬ìš´ë“œ í˜¸ë„ë¦¬ ã‚µã‚¦ãƒ³ãƒ‰ã‚¥ ãƒ›ãƒ‰ãƒª",
    "ãŠã—ã¾ã„ã€‚ã”è¦–è´ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸã€‚",
    "æœ€å¾Œã¾ã§è¦–è´ã—ã¦ãã ã•ã£ã¦ æœ¬å½“ã«ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚"
]

GREETINGS = [
    "ã‚ãã¼ï¼ã‚ãã¼ãƒ¼ï¼",
    "ã‚„ã£ãŸãƒ¼ï¼ãŠã—ã‚ƒã¹ã‚Šã—ã‚ˆãƒ¼",
    "ã‚„ã£ã»ãƒ¼ï¼ã“ã‚“ã«ã¡ã¯",
    "ã¡ã‚‡ã£ã¨ã­ã‚€ãŸã„ã‚ˆãƒ¼",
    "ã‚“ï¼Ÿãªã«ï¼Ÿãªã«ï¼Ÿ",
    "ã­ãˆã­ãˆã€ã“ã£ã¡ã¿ã¦ãƒ¼",
    "ã©ã†ã—ãŸã®ï¼Ÿ",
    "ã†ï½ã‚“ï¼ã‚ˆãå¯ãŸï½",
    "ã‚ãƒ¼ã„ï¼ã‚ãƒ¼ã„ï¼ãŠã­ãˆã¡ã‚ƒã‚“ï¼",
    "ãŠãªã‹ã—ã‚…ã„ãŸ"
]

# ------------------ éŸ³å£°é–¢é€£ ------------------ #

def record_audio():
    try:
        audio = sd.rec(int(SAMPLERATE * DURATION), samplerate=SAMPLERATE, channels=config.SPEAKER_ID, dtype=np.int16)
        sd.wait()
        wav.write(FILENAME, SAMPLERATE, audio)
        return True
    except Exception as e:
        print("âŒ éŒ²éŸ³ã‚¨ãƒ©ãƒ¼:", e)
        return False

def transcribe_audio():
    try:
        with open(FILENAME, "rb") as f:
            response = client.audio.transcriptions.create(
                model="whisper-config.SPEAKER_ID", file=f, language="ja", temperature=0.0
            )
        text = response.text.strip()
        return text
    except Exception as e:
        print("âŒ éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼:", e)
        return ""

# ------------------ Assistant API ------------------ #

def create_assistant_thread():
    thread = client.beta.threads.create()
    return thread.id

def get_assistant_response(thread_id, user_input):
    try:
        client.beta.threads.messages.create(thread_id=thread_id, role="user", content=user_input)
        run = client.beta.threads.runs.create(thread_id=thread_id, assistant_id=ASSISTANT_ID)
        while True:
            run_status = client.beta.threads.runs.retrieve(thread_id=thread_id, run_id=run.id)
            if run_status.status == "completed":
                break
            time.sleep(0.5)
        messages = client.beta.threads.messages.list(thread_id=thread_id)
        return messages.data[0].content[0].text.value
    except Exception as e:
        print("âŒ Assistant API ã‚¨ãƒ©ãƒ¼:", e)
        return "ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"

# ------------------ Voicevox ------------------ #

def synthesize_voice(text, speaker):
    try:
        params = {"text": text, "speaker": speaker}
        query_res = requests.post(f"{VOICEVOX_URL}/audio_query", params=params)
        if query_res.status_code != 200:
            print("âŒ ã‚¯ã‚¨ãƒªä½œæˆå¤±æ•—:", query_res.text)
            return None
        query = query_res.json()
        query.update({
            "speedScale": 1.1,
            "intonationScale": 2.0,
            "pitchScale": 0,
            "volumeScale": 1.0,
            "prePhonemeLength": 0,
            "postPhonemeLength": 0
        })
        synth_res = requests.post(f"{VOICEVOX_URL}/synthesis", params=params, json=query)
        if synth_res.status_code != 200:
            print("âŒ éŸ³å£°åˆæˆå¤±æ•—:", synth_res.text)
            return None
        return synth_res.content
    except Exception as e:
        print("âŒ Voicevoxã‚¨ãƒ©ãƒ¼:", e)
        return None

def amplify_audio(audio_data, factor):
    audio_array = np.frombuffer(audio_data, dtype=np.int16)
    amplified = (audio_array * factor).clip(-32768, 32767).astype(np.int16)
    return amplified.tobytes()

def play_audio(audio_data, factor=4.5):
    amplified = amplify_audio(audio_data, factor)
    wave = sa.WaveObject(amplified, num_channels=config.SPEAKER_ID, bytes_per_sample=2, sample_rate=24000)
    play = wave.play()
    play.wait_done()

# ------------------ ãƒ¡ã‚¤ãƒ³ä¼šè©±ãƒ«ãƒ¼ãƒ— ------------------ #

def speak_greeting():
    greeting = random.choice(GREETINGS)
    print(f"ğŸ™ï¸ ã‚ã„ã•ã¤: {greeting}")
    audio = synthesize_voice(greeting, SPEAKER_ID)
    if audio:
        play_audio(audio)

def speak_response(text):
    print(f"ğŸ¤– ãƒ‹ã‚³: {text}")
    audio = synthesize_voice(text, SPEAKER_ID)
    if audio:
        play_audio(audio)

def listen_and_talk_loop():
    last_valid_input_time = time.time()
    speak_greeting()
    thread_id = create_assistant_thread()

    while True:
        if not record_audio():
            continue

        text = transcribe_audio()
        now = time.time()

        if not text:
            print("ï¼ˆç„¡éŸ³èªè­˜ï¼‰")
        elif any(word in text for word in IGNORE_WORDS):
            print("ï¼ˆç„¡è¦–ãƒ¯ãƒ¼ãƒ‰æ¤œå‡ºï¼‰")
        else:
            print(f"ğŸ“ ãƒ¦ãƒ¼ã‚¶ãƒ¼: {text}")
            if any(stop_word in text for stop_word in STOP_WORDS):
                print("ğŸ‘‹ ã€ã‚¹ãƒˆãƒƒãƒ—ã€ã‚’æ¤œå‡ºã€‚ä¼šè©±ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
                speak_response("ã¾ãŸã­")
                print("STOP")
                sys.exit(0)
            reply = get_assistant_response(thread_id, text)
            speak_response(reply)
            last_valid_input_time = now

        if now - last_valid_input_time > INACTIVITY_TIMEOUT:
            print("â³ 300ç§’é–“æœ‰åŠ¹ãªä¼šè©±ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚çµ‚äº†ã—ã¾ã™ã€‚")
            speak_response("ã¾ãŸã­")
            print("STOP")
            sys.exit(0)

        time.sleep(config.SPEAKER_ID)

if __name__ == "__main__":
    listen_and_talk_loop()